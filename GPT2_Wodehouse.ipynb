{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip3 install torch numpy transformers datasets tiktoken wandb tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o18x5RwNREXn",
        "outputId": "e14d0dd0-5f6b-4d48-f41c-a6458d24c725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.41.0-py2.py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, dill, tiktoken, multiprocess, gitdb, GitPython, wandb, datasets\n",
            "Successfully installed GitPython-3.1.42 datasets-2.18.0 dill-0.3.8 docker-pycreds-0.4.0 gitdb-4.0.11 multiprocess-0.70.16 sentry-sdk-1.41.0 setproctitle-1.3.3 smmap-5.0.1 tiktoken-0.6.0 wandb-0.16.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install gpt-2-simple"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRyccC6KREdd",
        "outputId": "ee69dc02-1de8-444c-bb95-0359554d9006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpt-2-simple\n",
            "  Downloading gpt_2_simple-0.8.1.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (1.25.2)\n",
            "Collecting toposort (from gpt-2-simple)\n",
            "  Downloading toposort-1.10-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (2024.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.5.1->gpt-2-simple) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (3.2.2)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.8.1-py3-none-any.whl size=24557 sha256=335cb27dcd74803087e84358ba8e1f57c90c03318bc15bf27d4fa6acbca79600\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/6a/fe/10d3223f78d1ac3e4c83bb4c5e2d28dfb1789c2fb4cc7ea8d0\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.8.1 toposort-1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gpt_2_simple as gpt2\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "7u7Ow4GGREfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.download_gpt2()   # model is saved into current directory under /models/124M/\n",
        "\n",
        "print(gpt2.get_available_gpus())\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess,\n",
        "              '/content/input.txt',\n",
        "              steps=250,\n",
        "              restore_from = \"fresh\",\n",
        "              )"
      ],
      "metadata": {
        "id": "CAjp9RJYREnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63230a71-d186-425e-b829-79b5eaa8eced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 4.13Git/s]                                                     \n",
            "Fetching encoder.json: 1.05Mit [00:01, 585kit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 798Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:57, 8.71Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 2.98Git/s]                                               \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:01, 753kit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:01, 859kit/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/device:GPU:0']\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 81721 tokens\n",
            "Training...\n",
            "[1 | 6.44] loss=3.55 avg=3.55\n",
            "[2 | 8.49] loss=3.69 avg=3.62\n",
            "[3 | 10.54] loss=3.49 avg=3.58\n",
            "[4 | 12.59] loss=3.49 avg=3.55\n",
            "[5 | 14.64] loss=3.29 avg=3.50\n",
            "[6 | 16.69] loss=3.33 avg=3.47\n",
            "[7 | 18.74] loss=3.25 avg=3.44\n",
            "[8 | 20.81] loss=3.28 avg=3.42\n",
            "[9 | 22.88] loss=3.22 avg=3.39\n",
            "[10 | 24.94] loss=3.15 avg=3.37\n",
            "[11 | 27.02] loss=3.11 avg=3.34\n",
            "[12 | 29.10] loss=2.96 avg=3.31\n",
            "[13 | 31.18] loss=3.11 avg=3.29\n",
            "[14 | 33.27] loss=2.99 avg=3.27\n",
            "[15 | 35.36] loss=3.06 avg=3.26\n",
            "[16 | 37.44] loss=2.89 avg=3.23\n",
            "[17 | 39.54] loss=2.94 avg=3.21\n",
            "[18 | 41.63] loss=2.90 avg=3.19\n",
            "[19 | 43.74] loss=3.02 avg=3.18\n",
            "[20 | 45.84] loss=2.96 avg=3.17\n",
            "[21 | 47.95] loss=2.82 avg=3.15\n",
            "[22 | 50.07] loss=2.87 avg=3.14\n",
            "[23 | 52.18] loss=2.88 avg=3.13\n",
            "[24 | 54.30] loss=2.80 avg=3.11\n",
            "[25 | 56.43] loss=2.97 avg=3.10\n",
            "[26 | 58.56] loss=3.13 avg=3.11\n",
            "[27 | 60.69] loss=2.67 avg=3.09\n",
            "[28 | 62.83] loss=2.81 avg=3.08\n",
            "[29 | 64.98] loss=2.67 avg=3.06\n",
            "[30 | 67.12] loss=2.96 avg=3.06\n",
            "[31 | 69.28] loss=2.73 avg=3.04\n",
            "[32 | 71.43] loss=2.42 avg=3.02\n",
            "[33 | 73.59] loss=2.83 avg=3.01\n",
            "[34 | 75.75] loss=2.71 avg=3.00\n",
            "[35 | 77.91] loss=2.95 avg=3.00\n",
            "[36 | 80.08] loss=2.75 avg=2.99\n",
            "[37 | 82.24] loss=2.66 avg=2.98\n",
            "[38 | 84.41] loss=2.71 avg=2.97\n",
            "[39 | 86.58] loss=2.57 avg=2.96\n",
            "[40 | 88.76] loss=2.57 avg=2.95\n",
            "[41 | 90.94] loss=2.62 avg=2.94\n",
            "[42 | 93.13] loss=2.77 avg=2.94\n",
            "[43 | 95.31] loss=2.43 avg=2.92\n",
            "[44 | 97.50] loss=2.39 avg=2.91\n",
            "[45 | 99.70] loss=2.46 avg=2.89\n",
            "[46 | 101.90] loss=2.61 avg=2.89\n",
            "[47 | 104.10] loss=2.43 avg=2.87\n",
            "[48 | 106.30] loss=2.56 avg=2.87\n",
            "[49 | 108.51] loss=2.62 avg=2.86\n",
            "[50 | 110.71] loss=2.25 avg=2.84\n",
            "[51 | 112.92] loss=2.46 avg=2.83\n",
            "[52 | 115.14] loss=2.50 avg=2.83\n",
            "[53 | 117.36] loss=2.53 avg=2.82\n",
            "[54 | 119.59] loss=2.33 avg=2.81\n",
            "[55 | 121.82] loss=2.60 avg=2.80\n",
            "[56 | 124.05] loss=2.42 avg=2.79\n",
            "[57 | 126.29] loss=2.38 avg=2.78\n",
            "[58 | 128.54] loss=2.68 avg=2.78\n",
            "[59 | 130.79] loss=2.46 avg=2.77\n",
            "[60 | 133.04] loss=2.51 avg=2.77\n",
            "[61 | 135.30] loss=2.20 avg=2.76\n",
            "[62 | 137.55] loss=2.17 avg=2.74\n",
            "[63 | 139.81] loss=2.25 avg=2.73\n",
            "[64 | 142.08] loss=2.36 avg=2.73\n",
            "[65 | 144.35] loss=2.34 avg=2.72\n",
            "[66 | 146.63] loss=2.36 avg=2.71\n",
            "[67 | 148.91] loss=1.98 avg=2.70\n",
            "[68 | 151.20] loss=2.06 avg=2.68\n",
            "[69 | 153.49] loss=2.26 avg=2.67\n",
            "[70 | 155.79] loss=1.98 avg=2.66\n",
            "[71 | 158.10] loss=1.97 avg=2.65\n",
            "[72 | 160.42] loss=2.23 avg=2.64\n",
            "[73 | 162.73] loss=2.00 avg=2.63\n",
            "[74 | 165.05] loss=2.06 avg=2.62\n",
            "[75 | 167.37] loss=2.12 avg=2.61\n",
            "[76 | 169.70] loss=2.41 avg=2.60\n",
            "[77 | 172.03] loss=2.11 avg=2.59\n",
            "[78 | 174.35] loss=1.73 avg=2.58\n",
            "[79 | 176.68] loss=2.31 avg=2.57\n",
            "[80 | 179.00] loss=2.20 avg=2.57\n",
            "[81 | 181.31] loss=2.04 avg=2.56\n",
            "[82 | 183.62] loss=1.89 avg=2.54\n",
            "[83 | 185.93] loss=1.87 avg=2.53\n",
            "[84 | 188.24] loss=1.98 avg=2.52\n",
            "[85 | 190.55] loss=1.71 avg=2.51\n",
            "[86 | 192.85] loss=2.07 avg=2.50\n",
            "[87 | 195.15] loss=1.96 avg=2.49\n",
            "[88 | 197.45] loss=2.16 avg=2.49\n",
            "[89 | 199.75] loss=2.10 avg=2.48\n",
            "[90 | 202.04] loss=2.02 avg=2.47\n",
            "[91 | 204.32] loss=1.69 avg=2.46\n",
            "[92 | 206.61] loss=1.95 avg=2.45\n",
            "[93 | 208.90] loss=1.94 avg=2.44\n",
            "[94 | 211.19] loss=1.85 avg=2.43\n",
            "[95 | 213.47] loss=1.88 avg=2.42\n",
            "[96 | 215.76] loss=1.69 avg=2.41\n",
            "[97 | 218.05] loss=1.75 avg=2.40\n",
            "[98 | 220.34] loss=1.71 avg=2.39\n",
            "[99 | 222.64] loss=1.76 avg=2.38\n",
            "[100 | 224.93] loss=1.71 avg=2.37\n",
            "======== SAMPLE 1 ========\n",
            ".\n",
            "‘That is true. Kipper, as you say, is quite correct.’\n",
            "‘He does make a considerable contribution.’\n",
            "‘But the amount he puts in is too great.’\n",
            "‘I find it deeply upsetting.’\n",
            "‘I didn’t say you had to put in an extra seventy or so pounds.’\n",
            "‘Well, I only wrote a couple of lines, I was told.’\n",
            "‘However, don’t you agree that a man who is more at home at night and whose eyes are fixed on the prize than whoever gets it,\n",
            "and whose brain is in the game are two of the brightest men in the country in the same class?’\n",
            "‘You take it easy on my young friend. Do you mind if I start with you?’\n",
            "‘That would be the easy way out.’\n",
            "‘Do you know what, Bertie?’\n",
            "‘Just tell me.’\n",
            "‘Let me know what you think.’\n",
            "‘You can bring Wilbert back tomorrow.’\n",
            "‘My Aunt Dahlia will be there, looking aft as best she may at the gleam of my Spinoza on the screen.’\n",
            "‘In three days, you ask? It’s going to be a treat to have him with you.’\n",
            "‘Why not in three days?’\n",
            "‘A week is like a fever dream.’\n",
            "‘You don’t say?’\n",
            "‘But I can’t imagine that he’s all set.’\n",
            "‘How can he be?’\n",
            "‘You bet he’s not.’\n",
            "‘I told you he wasn’t all that and more.’\n",
            "‘But a week is like a fever dream.’\n",
            "‘But a week isn’t that not the case?’\n",
            "‘Well, to be blunt, no.’\n",
            "‘No, that’s true.’\n",
            "‘I mean, we’ve got Wilbert in the flesh today, but you know what he says about waiting for the next big thing. Always be ready. You’ll see.’\n",
            "‘You’ll.’\n",
            "‘I do,’ George Lanchester said in a hushed voice. ‘Come, come. Go and have a hartstooth.’\n",
            "‘A hartstooth is a car. One goes to see a hartstooth and the hartstooth gives his views on the country as if they knew it, and it’s only a little over a year since that car had been here. You know, the one that shot a bullet into a crowd of people?’\n",
            "I gave the old Wooster a wistful look.\n",
            "‘But where did the man come from?’\n",
            "‘He didn’t come from us.’\n",
            "‘He came from the countryside?’\n",
            "‘He would have been helpful.’\n",
            "‘I think he’s on borrowed time. It isn’t clear he left behind anything.’\n",
            "‘It’s difficult for a man like him to find a countryside friend.’\n",
            "‘But he does seem a bit like Wilbert to me.’\n",
            "‘Yes, that makes sense. He knows so little about the country that he can’t say he hasn’t a feel-good story to tell.’\n",
            "‘Well, the thing’s with the swum.’\n",
            "‘We all know where they lie. Theirs a lake, and on top of that there is a lake called Scarface. You can see that here, Aubrey Upjohn. It’s always there.’\n",
            "I was about to boil him down to the barest and say ‘That’s Wilbert Cream, plain and simple.’\n",
            "‘Well, then.’\n",
            "He didn’t like me, but he didn’t have to like me.\n",
            "‘All right, do as you like, or you can stick with the old Cream. If he still thinks there is a Scarface in the country, you are all good,’ I said.\n",
            "‘No, he is mistaken. This country is full of hounds.’\n",
            "‘And a gang of hounds.’\n",
            "‘Bare a wench as the underworld can be.’\n",
            "‘And what a gang of hounds we have here—’\n",
            "‘Bare an underworld.’\n",
            "�\n",
            "\n",
            "[101 | 239.26] loss=1.77 avg=2.36\n",
            "[102 | 241.56] loss=1.66 avg=2.35\n",
            "[103 | 243.86] loss=1.74 avg=2.34\n",
            "[104 | 246.17] loss=1.80 avg=2.33\n",
            "[105 | 248.48] loss=1.75 avg=2.32\n",
            "[106 | 250.78] loss=1.32 avg=2.31\n",
            "[107 | 253.09] loss=1.77 avg=2.30\n",
            "[108 | 255.40] loss=2.02 avg=2.29\n",
            "[109 | 257.72] loss=1.52 avg=2.28\n",
            "[110 | 260.03] loss=1.60 avg=2.27\n",
            "[111 | 262.34] loss=1.50 avg=2.26\n",
            "[112 | 264.65] loss=1.66 avg=2.25\n",
            "[113 | 266.96] loss=1.49 avg=2.24\n",
            "[114 | 269.27] loss=1.33 avg=2.23\n",
            "[115 | 271.59] loss=1.57 avg=2.22\n",
            "[116 | 273.91] loss=1.58 avg=2.21\n",
            "[117 | 276.23] loss=1.13 avg=2.19\n",
            "[118 | 278.54] loss=1.60 avg=2.19\n",
            "[119 | 280.85] loss=1.22 avg=2.17\n",
            "[120 | 283.17] loss=1.23 avg=2.16\n",
            "[121 | 285.49] loss=1.24 avg=2.14\n",
            "[122 | 287.80] loss=1.93 avg=2.14\n",
            "[123 | 290.11] loss=1.87 avg=2.14\n",
            "[124 | 292.42] loss=1.71 avg=2.13\n",
            "[125 | 294.73] loss=1.47 avg=2.12\n",
            "[126 | 297.04] loss=1.46 avg=2.11\n",
            "[127 | 299.35] loss=1.45 avg=2.10\n",
            "[128 | 301.65] loss=1.63 avg=2.10\n",
            "[129 | 303.96] loss=1.38 avg=2.09\n",
            "[130 | 306.27] loss=1.00 avg=2.07\n",
            "[131 | 308.58] loss=1.59 avg=2.07\n",
            "[132 | 310.89] loss=1.22 avg=2.05\n",
            "[133 | 313.19] loss=1.08 avg=2.04\n",
            "[134 | 315.49] loss=1.21 avg=2.03\n",
            "[135 | 317.82] loss=1.28 avg=2.02\n",
            "[136 | 320.14] loss=1.15 avg=2.01\n",
            "[137 | 322.44] loss=1.09 avg=2.00\n",
            "[138 | 324.74] loss=1.15 avg=1.98\n",
            "[139 | 327.05] loss=1.11 avg=1.97\n",
            "[140 | 329.35] loss=1.40 avg=1.97\n",
            "[141 | 331.66] loss=1.12 avg=1.95\n",
            "[142 | 333.96] loss=1.03 avg=1.94\n",
            "[143 | 336.25] loss=1.19 avg=1.93\n",
            "[144 | 338.56] loss=0.95 avg=1.92\n",
            "[145 | 340.85] loss=0.86 avg=1.91\n",
            "[146 | 343.16] loss=1.05 avg=1.89\n",
            "[147 | 345.45] loss=0.86 avg=1.88\n",
            "[148 | 347.76] loss=0.77 avg=1.87\n",
            "[149 | 350.05] loss=0.96 avg=1.86\n",
            "[150 | 352.35] loss=1.08 avg=1.85\n",
            "[151 | 354.65] loss=0.80 avg=1.83\n",
            "[152 | 356.95] loss=0.79 avg=1.82\n",
            "[153 | 359.25] loss=0.84 avg=1.81\n",
            "[154 | 361.55] loss=0.71 avg=1.79\n",
            "[155 | 363.85] loss=0.84 avg=1.78\n",
            "[156 | 366.16] loss=0.79 avg=1.77\n",
            "[157 | 368.46] loss=0.98 avg=1.76\n",
            "[158 | 370.77] loss=1.29 avg=1.75\n",
            "[159 | 373.07] loss=0.83 avg=1.74\n",
            "[160 | 375.37] loss=0.98 avg=1.73\n",
            "[161 | 377.67] loss=0.80 avg=1.72\n",
            "[162 | 379.96] loss=1.02 avg=1.71\n",
            "[163 | 382.27] loss=0.75 avg=1.70\n",
            "[164 | 384.57] loss=1.07 avg=1.69\n",
            "[165 | 386.87] loss=0.88 avg=1.68\n",
            "[166 | 389.17] loss=0.69 avg=1.67\n",
            "[167 | 391.47] loss=0.55 avg=1.65\n",
            "[168 | 393.77] loss=0.76 avg=1.64\n",
            "[169 | 396.07] loss=0.59 avg=1.63\n",
            "[170 | 398.37] loss=0.52 avg=1.62\n",
            "[171 | 400.68] loss=0.50 avg=1.60\n",
            "[172 | 402.98] loss=0.81 avg=1.59\n",
            "[173 | 405.28] loss=0.73 avg=1.58\n",
            "[174 | 407.58] loss=0.79 avg=1.57\n",
            "[175 | 409.89] loss=0.60 avg=1.56\n",
            "[176 | 412.19] loss=0.70 avg=1.55\n",
            "[177 | 414.50] loss=0.60 avg=1.54\n",
            "[178 | 416.80] loss=0.61 avg=1.53\n",
            "[179 | 419.10] loss=0.66 avg=1.52\n",
            "[180 | 421.41] loss=0.44 avg=1.51\n",
            "[181 | 423.71] loss=0.53 avg=1.49\n",
            "[182 | 426.01] loss=0.53 avg=1.48\n",
            "[183 | 428.32] loss=0.63 avg=1.47\n",
            "[184 | 430.62] loss=0.54 avg=1.46\n",
            "[185 | 432.92] loss=0.85 avg=1.45\n",
            "[186 | 435.23] loss=0.53 avg=1.44\n",
            "[187 | 437.53] loss=0.65 avg=1.43\n",
            "[188 | 439.83] loss=0.66 avg=1.43\n",
            "[189 | 442.13] loss=0.48 avg=1.41\n",
            "[190 | 444.43] loss=0.64 avg=1.40\n",
            "[191 | 446.73] loss=0.64 avg=1.40\n",
            "[192 | 449.04] loss=0.66 avg=1.39\n",
            "[193 | 451.34] loss=0.63 avg=1.38\n",
            "[194 | 453.64] loss=0.34 avg=1.37\n",
            "[195 | 455.93] loss=0.48 avg=1.36\n",
            "[196 | 458.24] loss=0.46 avg=1.35\n",
            "[197 | 460.55] loss=0.39 avg=1.33\n",
            "[198 | 462.85] loss=0.44 avg=1.32\n",
            "[199 | 465.15] loss=0.35 avg=1.31\n",
            "[200 | 467.46] loss=0.48 avg=1.30\n",
            "======== SAMPLE 1 ========\n",
            " him that he saw it coming and that he must not\n",
            "beran from the apportionment of blame and blame's aftermath to the receiver, and I saw no ground to stand on in this regard.\n",
            "‘No?’ said Aunt Dahlia. ‘Well, there’s Jeeves,’ I said, and I would have said’d’olly doofus if done in this doubtful light, sprang into action again in a flash, and Jeeves would have been\n",
            "one of those people in authority at that moment. ‘Your aunt must not have been thrilled.’\n",
            "‘Not yet,’ I said. ‘Twice in a row.’\n",
            "‘And now I’m talking… Are you listening, Bertie?’\n",
            "‘I am, if you may believe me, but what I’m hearing is being followed by many a Dear Sir and Phyllis is “This’s Tom.” Mark my words.\n",
            "This is wrong. This is extremely distressing.’\n",
            "‘I beseech you, M. Gordon, to call your psychiatrist immediately.’\n",
            "‘Rightly pronounced. It is that schizophrenia’s appearance that doctors are always\n",
            "working nights and weekends to try to save money. By nightfall, it rages on until morning, when you\n",
            "can rest assured that the girl will be home alone and feeling absolutely hopeless. And no mentalist would\n",
            "bewray an as yet unduly bright future with a limb amputated and no hope of averting a\n",
            "night where your teapot will hit the chuffingboard and the hound fish in the corner—a\n",
            "troubling end for all but the bravest. But try as we might to stave off what might come to that darling brain of yours, we couldn’t\n",
            "fathom any scenario in which the severe enough to break your peace, and there we were, sitting in that chair, waiting for the bang\n",
            "and hearing the bang.\n",
            "It was just that our being was made impatient and impatient by the fact that we did not appear at the far end of the\n",
            "table, just as we had been at the beginning, to be switched off for a moment.\n",
            "For once, the most recent of the dead, we were informed, ‘did shine a sparkle,’ ‘and a brief\n",
            "answer was made. I was not in error. There was an answer, and then silence fell on all at once.\n",
            "I turned to Bobbie.\n",
            "‘Mr. Wooster,’ I said, ‘I had an extremely wet dream.’\n",
            "‘Ewoks can solve problems wet dreams often become wet indeed.’\n",
            "‘Yes, sir.’\n",
            "‘You have a point.’\n",
            "‘I see. I wasn’t imagining it.’\n",
            "‘You continued into the nub, sir.’\n",
            "‘I should say this: I find the Upjohn quote I’m about to read all the rage.’\n",
            "‘Oh, jolly surprise.’\n",
            "‘Oh, jolly awakening.’\n",
            "‘I saw him off and over again at the lawn mower races, but this was the first time I’ve read anything by him\n",
            "and it’s like you.’\n",
            "Iineravigation had gone awry, and there was a great deal of breathing to do on this occasion, I could see that the\n",
            "hard work being done, but the most immediate task was to get the manuscript in the car and start\n",
            "starting. It had taken me an hour and a half getting the car working, and I had to admit that I put a lot\n",
            "back in waiting, as the Woosters tellingly say. I had assumed that this was the start of a new chapter,\n",
            "which would have involved a shake-up of the personnel lettering and leaving the rest of the\n",
            "matter to future chapters to iron out. I had also assumed that this, too, would involve ironing out\n",
            "my position on the Yeoman’s Wedding Question, which had so far escaped me.\n",
            "And of course I had assumed, if laziness and a mere eyelash of the maypole might have explained my\n",
            "shortage of a lieiter to my work. Odd, I must confess.\n",
            "But it did show that the upshot of this romp was not to say that I stood in the way of the tale,\n",
            "but rather that the upshot was that I had to rely on the Woosters to carry it along. And this was\n",
            "something I had been fruitlessly endeavoring to do since the first bath salts occurred, by sticking\n",
            "through my lunch glass with the tips of my fingers and not letting a pucker fall from\n",
            "the\n",
            "\n",
            "[201 | 480.61] loss=0.47 avg=1.29\n",
            "[202 | 482.91] loss=0.31 avg=1.28\n",
            "[203 | 485.21] loss=0.40 avg=1.27\n",
            "[204 | 487.51] loss=0.30 avg=1.26\n",
            "[205 | 489.81] loss=0.40 avg=1.25\n",
            "[206 | 492.11] loss=0.37 avg=1.24\n",
            "[207 | 494.41] loss=0.26 avg=1.23\n",
            "[208 | 496.71] loss=0.24 avg=1.22\n",
            "[209 | 499.01] loss=0.26 avg=1.21\n",
            "[210 | 501.32] loss=0.45 avg=1.20\n",
            "[211 | 503.61] loss=0.38 avg=1.19\n",
            "[212 | 505.91] loss=0.30 avg=1.18\n",
            "[213 | 508.21] loss=0.24 avg=1.17\n",
            "[214 | 510.51] loss=0.38 avg=1.16\n",
            "[215 | 512.82] loss=0.37 avg=1.15\n",
            "[216 | 515.12] loss=0.33 avg=1.14\n",
            "[217 | 517.42] loss=0.59 avg=1.14\n",
            "[218 | 519.72] loss=0.74 avg=1.13\n",
            "[219 | 522.01] loss=0.31 avg=1.12\n",
            "[220 | 524.31] loss=0.26 avg=1.11\n",
            "[221 | 526.61] loss=0.29 avg=1.10\n",
            "[222 | 528.91] loss=0.32 avg=1.09\n",
            "[223 | 531.20] loss=0.30 avg=1.09\n",
            "[224 | 533.50] loss=0.18 avg=1.08\n",
            "[225 | 535.80] loss=0.28 avg=1.07\n",
            "[226 | 538.10] loss=0.24 avg=1.06\n",
            "[227 | 540.40] loss=0.26 avg=1.05\n",
            "[228 | 542.70] loss=0.24 avg=1.04\n",
            "[229 | 544.99] loss=0.23 avg=1.03\n",
            "[230 | 547.30] loss=0.15 avg=1.02\n",
            "[231 | 549.60] loss=0.56 avg=1.02\n",
            "[232 | 551.90] loss=0.27 avg=1.01\n",
            "[233 | 554.21] loss=0.26 avg=1.00\n",
            "[234 | 556.52] loss=0.16 avg=0.99\n",
            "[235 | 558.81] loss=0.23 avg=0.98\n",
            "[236 | 561.11] loss=0.21 avg=0.97\n",
            "[237 | 563.41] loss=0.21 avg=0.96\n",
            "[238 | 565.72] loss=0.20 avg=0.96\n",
            "[239 | 568.02] loss=0.27 avg=0.95\n",
            "[240 | 570.32] loss=0.17 avg=0.94\n",
            "[241 | 572.62] loss=0.24 avg=0.93\n",
            "[242 | 574.92] loss=0.29 avg=0.93\n",
            "[243 | 577.22] loss=0.22 avg=0.92\n",
            "[244 | 579.52] loss=0.35 avg=0.91\n",
            "[245 | 581.83] loss=0.29 avg=0.90\n",
            "[246 | 584.13] loss=0.22 avg=0.90\n",
            "[247 | 586.43] loss=0.27 avg=0.89\n",
            "[248 | 588.72] loss=0.26 avg=0.88\n",
            "[249 | 591.03] loss=0.14 avg=0.87\n",
            "[250 | 593.34] loss=0.23 avg=0.87\n",
            "Saving checkpoint/run1/model-250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "single_text = gpt2.generate(sess, return_as_list=True)[0]\n",
        "print(single_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u_51eR_REpa",
        "outputId": "b9f02a93-5cca-48a3-93d9-4779dfd384b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Well, this isn’t helpful. You seem to have forgotten that we met in Switzerland, and that your intention was to drive us crazy. You’d have written to me to tell me your plans had gone black. Quit me, young man. Quit my spark, if you’re interested. Quit my charm, if you’re interested. Quit my air of mystery. Quit my air of terror. Quit my air of relief. Quit my ace, if you’re interested. Quit my all-rounder. Quit my all-rounder. Quit my all-rounder. Quit my all-rounder. Quit my all-rounder. Quit my all-rounder. Quit my ace, if you’re interested. Quit my all-rounder. Quit my all-rounder. Quit my all-rounder. Quit my ace, if you’re interested. Quit my all-rounder. Quit my all-rounder. Quit my all-rounder. Quit my all-rounder. Quit my all-rounder. Quit my ace, if you’re interested. Quit my all-rounder. Quit my all-rounder. Quit my all-rounder. Quit my all-rounder. Quit my all-rounder.\n",
            "Well, I’ll tell you what you’re going to do. If you want to get out early, be nice to me and tell my Mother that I hush-hush broke off the negotiations and that somebody——\n",
            "Ma Cream. You’re going to have to say either “Yes, Mr. Wooster” or you’ll be in\n",
            "demands.” If you want to remain in the dark for long, just give me a ring or a word or a\n",
            "ring and I will trace the line between official silence and official silence. When I am all of a\n",
            "bit of a muddle, my words shall ring like harangues, and I shall be nameless. When I am all of a\n",
            "bit of a muddle, my words shall be those of a friend, a bahuntimes twee, to thy Mother. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine. Mine\n",
            "’Most attractive woman in the world, eh?’\n",
            "I started.\n",
            "‘Hullo, have you seen Phyllis?’\n",
            "‘She has just arrived.’\n",
            "‘Reached the tea table.’\n",
            "‘Reached the tea table.’\n",
            "‘And a moment later…'\n",
            "‘I’ll give you one tip. If you have ever gazed at a dying cat, you will see that it is not content with a corpse. Its soul’s a mess.’\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IMhE8qPBzADd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VoRs1w1MzAKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fhIuFkzqzANX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vPCZvZ7WzAP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w7nILDV8zASl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "keosZumrzAVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vua5LlRKzAXR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}